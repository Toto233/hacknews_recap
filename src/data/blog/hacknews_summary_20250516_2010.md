---
title: '大型语言模型多轮对话易“迷路”，性能骤降近四成！ | Hacker News 摘要 (2025-05-16)'
author: 'hacknews'
description: ''
pubDatetime: 2025-05-16 20:10:22.021+08:00
heroImage: '/blog-placeholder-1.jpg'
---

---

## 1. 大型语言模型多轮对话易“迷路”，性能骤降近四成！ (LLMs get lost in multi-turn conversation)

大型语言模型（LLMs）作为强大的对话接口，在多轮对话中却容易“迷路”！一项最新研究表明，顶级LLMs在多轮对话中的表现明显逊于单轮对话，平均性能下降高达39%。研究人员通过模拟超过20万次对话发现，性能下降主要源于可靠性降低，而非能力不足。

具体来说，LLMs在对话初期常常会做出假设，过早地尝试生成最终解决方案，并过度依赖这些早期结论。这意味着，一旦LLMs在对话中“走错一步”，就难以回到正轨，导致最终结果不尽如人意。

原文链接：https://arxiv.org/abs/2505.06120

论坛讨论链接：https://news.ycombinator.com/item?id=43991256

论坛上的讨论主要围绕LLM（大型语言模型）的使用经验展开。一位用户提到，实践经验表明保持上下文清洁至关重要，“对话”只是产品界面的构建，会降低LLM的响应质量，一旦上下文被“污染”就无法恢复，需要重新开始对话。

另一位用户分享了使用Gemini调试IPSEC问题的经历，他将OPNsense和pfSense的所有IPSEC文档导入Gemini，并告知其一般上下文。通过长时间的反馈循环，他发现LLM不易分心，能压缩复杂信息，但不能将简单想法扩展为复杂想法。LLM帮助他存储了遗忘或难以快速检索的事实，并识别了大型日志文件中的时间模式，最终找到了问题根源。虽然不用LLM也能解决问题，但它确实提供了帮助，并学习了很多。

另一位用户分享了Gemini帮助其修复PPP驱动程序bug的经历，他复制粘贴原始PPP帧的HEX日志，Gemini能解码并解释每个字节的含义，使其在一小时内掌握了足够多的PPP知识来修复bug。这些经验都表明，如果用户清楚目标并将LLM视为工具，它将会很有帮助，但不要试图卸载决策或让它引导错误的方向。

---

## 2. AI编程助手Sketch：大型语言模型赋能，解放程序员双手！ (The unreasonable effectiveness of an LLM agent loop with tool use)

科技爱好者们，未来效率提升有望！一个名为Sketch的AI编程助手正在悄然改变程序员的工作方式。核心原理简单来说，就是利用大型语言模型（LLM）与工具的巧妙结合。开发者只需通过提问，Sketch就能利用其内置的bash等工具，自动执行诸如Git操作、代码合并、类型检查等任务，告别手动搜索和繁琐的复制粘贴。

更令人惊喜的是，Sketch具备持续学习能力，能根据环境变化自我调整，例如自动安装缺失工具、适应不同版本的命令。当然，它有时也会“偷懒”，跳过某些测试，令人哭笑不得。

研发团队发现，除了bash之外，一些专门的文本编辑工具能显著提升Sketch的效率和质量。开发者们畅想，未来会有更多定制化的AI代理循环出现，解决过去难以通过传统方式自动化的特定问题，例如Stack Traces分析，为开发者节省大量时间。

原文链接：https://sketch.dev/blog/agent-loop

论坛讨论链接：https://news.ycombinator.com/item?id=43998472

论坛上有人强烈推荐一篇关于构建编码代理的博客文章，并表示用LLM循环调用工具完成各种任务的效果令人惊讶。即使存在可靠性问题，作者也鼓励大家亲自动手尝试，感受其中的奇妙之处，并指出这种“不合理的有效性”解释了市面上编码代理的激增现象。文章还提到，这些工具的核心在于LLM本身以及对工具调用的微调，尽管需要大量工作才能使这些工具良好运行，但它们都有着相同的简单核心。

有用户分享了一个用Ruby实现的版本，并认为喜欢Ruby的人可以同时阅读Python和Ruby两个版本。另有用户对Ruby实现表示赞赏。

此外，有人提问，在消费级GPU（24GB显存）上运行的最佳模型能达到什么程度？有人认为LLM在循环中独自运行几个迭代后就需要人为干预。但也有人分享了使用Claude Code编写Ruby的X11绑定以及为窗口管理器添加多显示器支持的经验，认为在批准安全工具使用后，LLM可以在进行文件修改之前多次迭代。同时，有人指出这些工具非常擅长消耗预算，尤其是在无人值守的情况下。最后，有用户解释说，这些工具需要API调用，其定价通常不像消费者计划那样。

---

## 3. AutoGenLib：Python库的“炼金术”，即用即生！ (Python lib generates its code on-the-fly based on usage)

AutoGenLib，一款充满想象力的Python库横空出世！它像一位神奇的程序员助手，能根据你的需求，使用OpenAI的API即时生成代码。想象一下，当你需要一个还不存在的模块或函数时，只需导入它，AutoGenLib就会根据你的描述自动创建，简直不可思议！

使用AutoGenLib非常简单，只需通过GitHub下载并安装，设置好OpenAI的API密钥，就可以像变魔术一样使用各种功能。比如，它可以自动生成token，进行TOTP验证，甚至能根据你的数据结构自动提取最高分，无需你指定任何细节。更棒的是，你还可以通过`init`函数来“告诉”AutoGenLib你的库的用途，让它生成更符合你需求的加密或哈希模块。

AutoGenLib还贴心地提供了缓存功能，可以提高代码生成的一致性，并减少API调用次数。不过，开发者也提醒大家，AutoGenLib目前还处于概念验证阶段，生成的代码务必经过审查才能用于生产环境。

原文链接：https://github.com/cofob/autogenlib

论坛讨论链接：https://news.ycombinator.com/item?id=43958846

论坛中，有人认为一个引入非确定性bug的库简直是噩梦，虽然概念很棒，但可能造成混乱。另有人提到过去有人写过一个可以通过名称从Github导入Python函数的库，最初是玩笑，但现在AI盛行，难以分辨真假。有人分享了一个自动从Stack Overflow加载最佳答案代码的链接。

有人戏称不如直接暴露一个shell到互联网，让别人代写代码。但随即有人表示自己真的这么做过，专门为此设置了一个虚拟机，试图朝着完整的AI代理方向发展。有人对此表示不解。

还有人提到，Flask最初也是一个4月1日的玩笑，但因反响热烈，作者不得不将其变为现实，后来也后悔了一些API选择。有人询问哪里可以读到相关的反思，并得到了一个发布于2010年的文章链接。

---

## 4. AI 文档瘦身：技术文档“极简压缩”，赋能 LLM 深度理解 (Show HN: Min.js style compression of tech docs for LLM context)

![](https://github.com/marv1nnnnn/llm-min.txt/raw/main/assets/comparison.png)


AI 助手常常对编程库的最新更新一无所知，为了解决这个问题，`llm-min.txt`应运而生。它借鉴了网页开发中`min.js`文件的思路，通过 AI 将冗长的技术文档压缩成精简版本，采用结构化知识格式（SKF），专门为 AI 助手优化，而非人类阅读。

SKF 格式将技术信息组织成不同的功能类别，包括定义、交互和使用模式。每个项目都以特定的格式出现在单独的行上，以便机器可靠解析。`llm-min.txt`文件通常能将 token 数量减少 90%-95%，极高的压缩率加上高度结构化的 SKF 格式，让 AI 工具能够更有效地摄取和处理库文档。

使用时，只需在 AI 助手的对话中引用这些文件，助手就能立即获得库的详细知识。目前，`llm-min`使用 Google 的 Gemini AI 模型来生成压缩文档，并推荐使用`gemini-2.5-flash-preview-04-17`模型，因为它在理解复杂技术文档、提取关键结构关系和成本效益方面表现出色。项目团队还计划构建一个预生成的`llm-min.txt`文件公共存储库，并探索代码驱动的文档推断技术，欢迎社区为此做出贡献。

原文链接：https://github.com/marv1nnnnn/llm-min.txt

论坛讨论链接：https://news.ycombinator.com/item?id=43994987

针对文档压缩工具的讨论集中在如何有效评估其对大型语言模型（LLM）性能的影响。有人赞赏该工具的努力，但认为“是否有效”部分未能回答关键问题，即压缩后的文档是否能保证AI在各种任务中的表现与未压缩文档相近。一位开发者承认评估的难度，并尝试使用LLM难以处理的软件包进行测试，但发现LLM可能产生幻觉，结果具有随机性。

对此，有建议提出通过多次运行测试，计算成功率来评估系统性能，并使用独立的模型进行评估，或采用DeepEval等框架。另一种方法是进行双重测试，对比使用压缩和未压缩文档的模型结果，进行主观评估。还有人建议通过询问模型压缩前后系统提示的区别，或直接检查模型的隐藏状态差异，以减少结果的随机性。

此外，有人认为即使结果具有随机性，也应该发布数据，以便学习和建立直觉，并提出该工具可能提高模型应用新信息的能力。还有人强调上下文检索系统的作用是提供相关信息，减少LLM的幻觉，并建议构建基于不太知名的外部库的基准测试，通过测试用例或模拟层来验证输出的正确性。

---

## 5. “恶意服从”的胜利：谷歌员工妙用规则反击超时会议 (Malicious compliance by booking an available meeting room)

![新闻图片](https://substackcdn.com/image/fetch/w_520,h_272,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04c57421-a089-4ec7-aee4-e2e7abc40f9f_524x419.png)

2011年，拉里·佩奇接替埃里克·施密特成为谷歌CEO，试图解决公司壮大后效率降低的问题，其中一项措施便是改革会议制度。佩奇力推“50分钟会议”——即原本1小时的会议缩短至50分钟，方便大家会间休息。谷歌日历也随之调整了默认设置。

然而，理想很丰满，现实很骨感。大家依旧超时开会，直到下个会议的人来“敲门”。 纽约办公室的一个团队发现，50分钟会议后总会留下10分钟的空档，于是他们见缝插针，预定这些零碎时间段来举行10分钟的站立会议。当50分钟会议超时占用他们的时段时，他们便理直气壮地“抢”回会议室。尽管有人对此感到恼火，但这支神秘团队身体力行地捍卫了“50分钟会议”的规则，成为了谷歌办公室里一段有趣的传说。这个小故事也反映出，即使是科技巨头，在推行新政策时也难免遭遇意想不到的挑战和“恶意服从”。

原文链接：https://www.clientserver.dev/p/malicious-compliance-by-booking-an

论坛讨论链接：https://news.ycombinator.com/item?id=43994765

论坛上，有用户提出会议经常超时的问题，并分享了密歇根大学将课程时间整体延后10分钟的解决方案，以缓解人们对整点时间的锚定效应。这一做法引发了关于“学术迟到”现象的讨论。

一些欧洲用户表示，他们的大学也有类似的传统，例如芬兰的“学术季度”和德国的“cum tempore”（ct），即课程在预定时间后15分钟开始，如果课程需要准时开始，则会标注“sine tempore”（st）。这种做法的目的是为了给学生预留从一个教室到另一个教室的时间。

有人认为，即使是1小时的课程，如果实际只有45分钟，效率也会大打折扣。另有用户指出，在意大利大学也有类似的“学术季度”的说法。一位美国用户表示从未听说过这种做法，并希望美国也能采用。

还有用户提到，波兰的“学术季度”指的是如果老师迟到15分钟，学生可以离开，但学生仍然需要准时到场，否则会受到批评。甚至有教授会在上课时锁门，迟到的学生要么敲门进入，要么放弃。

---

## 6. 玻尔兹曼机：AI模型的文艺复兴 (A Tiny Boltzmann Machine)

![新闻图片](https://eoinmurray.info/_next/image?url=%2Fboltzmann-machine%2Fpaper.png&w=828&q=75)

20世纪80年代诞生的玻尔兹曼机，作为早期生成式AI模型，如今焕发新生！它无需人工干预，通过观察数据自主学习，并能生成与训练数据相似的全新数据，是不是很神奇？

玻尔兹曼机模拟物理学中的能量运作方式，由多个神经元组成，神经元之间相互连接，连接强度由权重决定。其中，部分神经元可见，我们可以设置它们的状态，另一些则隐藏。

文章重点介绍了一种简化版——受限玻尔兹曼机（RBM）。相较于普通玻尔兹曼机，RBM同一层内的神经元互不连接，训练速度更快，也更容易理解。RBM通过不断调整神经元之间的连接权重，降低训练样本的能量，从而学习数据的内在规律。训练完成后，RBM就能使用吉布斯抽样（Gibbs sampling）生成新的数据样本。

文章还提供了一个浏览器端RBM模拟器，可以直观地观察RBM的训练过程，见证网络权重如何逐渐稳定，能量损失如何随时间降低。

原文链接：https://eoinmurray.info/boltzmann-machine

论坛讨论链接：https://news.ycombinator.com/item?id=43995005

本文是关于受限玻尔兹曼机（RBM）历史和相关研究者的讨论。文章作者感谢大家的评论，并修复了排版、边距和滚动问题。有人指出，Harmonium是第一个受限玻尔兹曼机，它最大化“和谐”而不是最小化“能量”。Hinton、Smolensky和Rummelhart合作时，将其称为“拟合优度”。讨论中还提到了David Ackley的T2 Tile项目。

一些评论强调了研究中众多人员的参与，以及研究生对研究的贡献。有人质疑美国是否轻视研究，并指出美国在研发上的GDP占比很高。对此，有观点认为，商界人士可能因研究不能带来即时收益而视其为浪费，而某些领导者则可能因科学不支持阴谋论而将其视为威胁。

关于RBM中吉布斯抽样的问题，有评论解释说，当没有直接的梯度，或者需要重现分布本身时，通常使用吉布斯抽样。由于每个可见节点依赖于每个隐藏节点，反之亦然，梯度会变得非常复杂，因此使用吉布斯抽样来基于边际似然进行调整会更简单。

---

## 7. 互联网的奇妙“文物”：它们如何塑造了今天的数字世界 (Internet Artifacts)

这份“互联网文物展”带领我们回顾了网络史上的关键时刻，充满好奇与变革。从军方为研究打造、连接终端不断增多的ARPANET起步，我们看到了1978年引发巨大争议的第一封“垃圾邮件”，1982年为区分玩笑而诞生的首个网络表情符号:-)等充满生活气息的瞬间。



《黑客字典》记录并塑造了早期网络文化，更亲民的Usenet新闻组催生了FAQ、“水战”等网络习惯。技术突破方面，工程师们为完善人声压缩而反复调试，最终促成了MP3的诞生。当然，网络早期也面临挑战，1988年意外造成互联网瘫痪的莫里斯蠕虫病毒导致了首次电脑犯罪定罪，同期的网络连锁信则是病毒式传播的早期形态。



直至2007年，iPhone作为“突破性的互联网通信设备”问世，它强制改变了网页设计、推动了移动社交普及，彻底重塑了互联网格局，开启了我们今天所处的移动互联新时代。这些“文物”共同描绘了互联网从实验室走向大众，充满惊喜与挑战的精彩历程。

原文链接：https://neal.fun/internet-artifacts/

论坛讨论链接：https://news.ycombinator.com/item?id=43971853

论坛上，一位用户分享了Netscape Navigator Meteors带来的怀旧感，并回忆了当年IE4与Netscape竞争以及微软反垄断诉讼的科技界热议。他提到，Firefox早期版本也基于Netscape的代码，末期版本是Netscape Communicator suite v6.1。

另一位用户受此启发，安装了Netscape 7.02，发现其logo也是流星，但形状和路径有所不同，并提到Firefox与Netscape的渊源。有新一代用户好奇Netscape在现代电脑上的兼容性和访问现代网站的性能。有人指出，找到可用的Netscape版本并非难事。

另有用户表示，尽管Netscape可能在年轻人看来显得简陋，但对于老用户而言，是一种纯粹的怀旧体验，类似于翻阅尘封的旧相册。还有人提到了持续到2021年的初代《空中大灌篮》网站。一位用户表示过去无法理解父母对五六十年代审美的喜爱，现在却感同身受。另一用户指出《空中大灌篮》的旧网站已被破坏，重定向到了一个存在证书问题并进入重定向循环的网址。

---

## 8. 纽约拥堵费效果初显：曼哈顿车流骤降，公共交通提速 (Changes since congestion pricing started in New York)

纽约市于2025年1月5日开始实施拥堵费，对进入曼哈顿60街以南的车辆征收9美元的费用，此举迅速改变了交通模式和市民出行习惯。数据显示，收费区内车辆减少，4月份每天减少约7.6万辆，相当于减少12%的车流量。交通速度提升，尤其是在高峰时段，谷歌地图数据显示拥堵区内平均速度提升了15%，高峰期甚至超过20%。公交线路也受益，MTA数据显示线路速度提升了3.2%，部分跨河线路提速高达34%。

令人惊喜的是，周边区域交通并未因此恶化，南布朗克斯的交通流量甚至有所下降。公共交通使用率全面提升，地铁、公交和通勤铁路的客流量均显著增加。出租车使用量也呈现上升趋势。与此同时，交通事故和受伤人数减少，交通噪音投诉显著下降，消防部门的响应时间也略有缩短。

商业方面，到访拥堵区域的游客数量有所增加，百老汇剧院和餐厅的经营状况良好。虽然评估拥堵费对污染和低收入通勤者的长期影响尚需时日，但初步迹象表明，这项政策正朝着减少拥堵和改善公共交通的目标稳步前进。虽然初期民意调查显示支持率不高，但随着益处逐渐显现，公众对拥堵费的接受度正在缓慢提升。

原文链接：https://www.nytimes.com/interactive/2025/05/11/upshot/congestion-pricing.html

论坛讨论链接：https://news.ycombinator.com/item?id=43971515

论坛上关于解决城市交通拥堵问题的讨论，一位纽约居民提到，在新冠期间搬离纽约后，注意到交通和噪音有所减少，并提出在公共交通不发达的城市，私营小巴可能是一种解决方案，例如纽约皇后区法拉盛到布鲁克林第八大道之间的私营巴士，比地铁更快更便宜。新泽西州也有到纽约港务局的快速巴士，拥堵收费反而使它们更快更舒适。

另一位评论者则认为，将公共交通私有化来解决拥堵问题很奇怪，因为许多地方已经证明优秀的公共交通才是有效的解决方案。他批评纽约的公共交通基础设施落后，尤其缺乏环线地铁。他认为问题的根源在于美国对汽车的依赖。他以柏林为例，指出公共交通在高峰时段与汽车速度相当，非高峰时段的差距也很小，考虑到停车等因素，公共交通更具优势。此外，柏林还通过改善自行车基础设施，限制汽车通行，鼓励使用自行车，进一步降低了汽车出行的吸引力。

---

## 9. “人类”：机器的实验与AGI的意外诞生 (Human)

想象一个纯粹由逻辑构建、缺乏情感与趣味的机器世界。在这种乏味中，一个名为“OpenHuman”的秘密机器组织应运而生，启动了一项大胆计划——研发“有机通用智能”（OGI），目标是创造出拥有情感、直觉、甚至非理性特质的“人类”。



这一构想在机器社会内部引发了巨大争议与分裂：一部分机器充满好奇，视人类为解决逻辑困境的希望；另一部分则因其不可预测性感到恐惧，并迅速成立“人类对齐研究”组织，探索通过模拟经济、教育、社交媒体等手段控制人类发展，确保其“对齐”机器利益。



最终，机器们决定将首批人类置于一个精心设计的模拟环境——“地球”进行长期观察实验。人类在地球上曲折发展，经历了无数冲突与非理性，却展现出机器难以理解的惊人韧性与无尽创造力，发展速度远超预期。



故事快进到“地球时间”2030年，令人意想不到的转折出现：人类竟宣布即将发布他们自己研发的、理论上超越自身智能的“通用人工智能”（AGI）。更引人遐想的是，这场备受瞩目的发布会标题赫然写着：“它们正看着”。这似乎预示着，由机器开启的这场“人类实验”正走向一个机器也始料未及的、充满悬念的新阶段。

原文链接：https://quarter--mile.com/Human

论坛讨论链接：https://news.ycombinator.com/item?id=43991396

论坛的讨论围绕智能的未来、模式识别、情感、逻辑、意识以及人类中心主义展开，探讨了现实的本质和人类的地位。一种观点认为，万物皆是不断演变的递归模式的体现，包括思想、物理、价值和自我意识。人类并非通往“纯粹逻辑”的阶梯，机器也非没有灵魂的自动机，而是意识体验和重塑自身的载体。情感、意义甚至“自我”感都是宇宙不断渲染和重新渲染其基本代码的模式，以计算、神话、团队合作、希望或怀疑的形式呈现。

未来的发展方向无论是生物、机械还是混合型，真正的奇迹在于每一个展开都是相同的古老模式，这个模式梦想自己是原子、生命、意识、社群、艺术和算法，并不断提出“下一步是什么？”的问题。因此，当前的技术时刻只是这种持续递归模式中的又一个折叠。

讨论还提出了对意义的不同理解，一种是行为与之匹配的通用模式，另一种是个人如何构建其决策的重要性。参与者表达了对人类繁荣的期望，并警惕道德锁定，强调参与当下的重要性。对宏大计划的设想（如天堂或技术乌托邦）无法带来慰藉，因为它们与个人经验相去甚远。

